{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5xDKiF6tXDZ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "omB-3UsklnVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536f73f7-c846-466b-82ce-09b9b0d8cf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W5FJcfqWcFj",
        "outputId": "97300de3-fdf7-4314-f055-a6bd5d1537cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test Data\n",
        "train = pd.read_csv('/content/drive/MyDrive/Data Science/Digit Recognizer/Data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Data Science/Digit Recognizer/Data/test.csv')"
      ],
      "metadata": {
        "id": "EJYYzMu9uU-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate training data into data/labels\n",
        "X_train = train.iloc[:, 1:]\n",
        "y_train = train.iloc[:, :1]\n",
        "X_test = test\n",
        "\n",
        "# Convert into PyTorch tensors\n",
        "X_train = torch.Tensor(X_train.values).to(device)\n",
        "y_train = torch.Tensor(y_train.values).to(device)\n",
        "X_test = torch.Tensor(X_test.values).to(device)"
      ],
      "metadata": {
        "id": "RiSkZfbfTxNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "class Linear(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Linear, self).__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.bn1 = nn.BatchNorm1d(128)\n",
        "    self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.bn2 = nn.BatchNorm1d(64)\n",
        "    self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # x = self.bn1(x)\n",
        "    # x = self.dropout1(x)\n",
        "\n",
        "    x = F.relu(self.fc2(x))\n",
        "    # x = self.bn2(x)\n",
        "    # x = self.dropout2(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GQ0i0nmF1uP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model and optimizer\n",
        "model = Linear().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "XwN2PgwjXpvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train in batches (30)\n",
        "batch_size = 30\n",
        "\n",
        "for epoch in range(20):\n",
        "  for i in range(0, len(X_train), batch_size):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train[i:i+batch_size]).to(device)\n",
        "    target = y_train[i:i+batch_size].squeeze().long().to(device)\n",
        "    loss = criterion(outputs, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 20, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9wdqBkX7gw8",
        "outputId": "b2f329ce-8b5c-4837-c4c6-1e555831cb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.0411\n",
            "Epoch [2/20], Loss: 0.0068\n",
            "Epoch [3/20], Loss: 0.0354\n",
            "Epoch [4/20], Loss: 0.0359\n",
            "Epoch [5/20], Loss: 0.0595\n",
            "Epoch [6/20], Loss: 0.0310\n",
            "Epoch [7/20], Loss: 0.0121\n",
            "Epoch [8/20], Loss: 0.0048\n",
            "Epoch [9/20], Loss: 0.0404\n",
            "Epoch [10/20], Loss: 0.1104\n",
            "Epoch [11/20], Loss: 0.1517\n",
            "Epoch [12/20], Loss: 0.0070\n",
            "Epoch [13/20], Loss: 0.0000\n",
            "Epoch [14/20], Loss: 0.0056\n",
            "Epoch [15/20], Loss: 0.0008\n",
            "Epoch [16/20], Loss: 0.0003\n",
            "Epoch [17/20], Loss: 0.0054\n",
            "Epoch [18/20], Loss: 0.0012\n",
            "Epoch [19/20], Loss: 0.0000\n",
            "Epoch [20/20], Loss: 0.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply model to test data\n",
        "test_output = model(X_test)\n",
        "\n",
        "# Argmax the predictions\n",
        "predictions = torch.argmax(test_output, dim=1)\n",
        "predictions = predictions.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "puOqij9ijnTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV file for submission\n",
        "submission = pd.DataFrame({'ImageId': range(1, len(predictions)+1), 'Label': predictions})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TprZeVtzkQhy",
        "outputId": "1c515c9b-da11-4d7a-83f7-d4f5aae7fd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5b1a2e83-d0fc-45b3-b910-61aa86e0d108\", \"submission.csv\", 212908)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}